# Vast.ai Template: LLaMA Factory on Vast.ai Base Image
# Features: Instance Portal, TLS, Jupyter, Syncthing, TensorBoard (built-in)
ARG VASTAI_VERSION=cuda-12.4.1-auto
FROM vastai/base-image:${VASTAI_VERSION}

USER root

# Install LLaMA Factory and dependencies (torchvision for VLM support)
RUN pip install --no-cache-dir llamafactory torchvision && \
    rm -rf /root/.cache/pip /tmp/*

# Install logging/tracking tools + flash-attention
ARG FLASH_ATTN_VERSION=2.7.4
ARG FLASH_ATTN_WHEEL=https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.5.4/flash_attn-2.7.4%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl
RUN pip install --no-cache-dir wandb mlflow "optimum>=1.24.0" && \
    (pip install --no-cache-dir --no-deps ${FLASH_ATTN_WHEEL} \
    || echo "WARNING: flash-attention ${FLASH_ATTN_VERSION} install failed - continuing without it") && \
    (pip install --no-cache-dir --no-deps "gptqmodel>=2.0.0" logbar \
    || echo "WARNING: gptqmodel install failed - install at runtime with: pip install --no-deps gptqmodel logbar") && \
    rm -rf /root/.cache/pip /tmp/*

# Persist env vars for SSH/Jupyter sessions and auto-login wandb
COPY scripts/vastai-env.sh /etc/profile.d/vastai-env.sh
RUN chmod +x /etc/profile.d/vastai-env.sh

# Switch back to non-root user (vast.ai default)
USER user

WORKDIR /workspace
