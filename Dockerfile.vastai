# Vast.ai Template: LLaMA Factory on Vast.ai Base Image
# Features: Instance Portal, TLS, Jupyter, Syncthing, TensorBoard (built-in)
ARG VASTAI_VERSION=cuda-12.4.1-auto
FROM vastai/base-image:${VASTAI_VERSION}

USER root

# Install LLaMA Factory and dependencies
RUN pip install --no-cache-dir llamafactory && \
    rm -rf /root/.cache/pip /tmp/*

# Install logging/tracking tools + flash-attention
ARG FLASH_ATTN_VERSION=2.7.4
ARG FLASH_ATTN_WHEEL=https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.5.4/flash_attn-2.7.4%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl
RUN pip install --no-cache-dir wandb mlflow && \
    (pip install --no-cache-dir --no-deps ${FLASH_ATTN_WHEEL} \
    || echo "WARNING: flash-attention ${FLASH_ATTN_VERSION} install failed - continuing without it") && \
    rm -rf /root/.cache/pip /tmp/*

# Auto-login wandb if API key is set (add to supervisor or entrypoint hook)
RUN echo '[ -n "$WANDB_API_KEY" ] && python -c "import wandb; wandb.login(key=\"$WANDB_API_KEY\")" 2>/dev/null || true' >> /etc/profile.d/wandb.sh && \
    chmod +x /etc/profile.d/wandb.sh

# Switch back to non-root user (vast.ai default)
USER user

WORKDIR /workspace
